{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List avaliable amazon bedrock models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Lists the available Amazon Bedrock models.\n",
    "\"\"\"\n",
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def list_foundation_models(bedrock_client):\n",
    "    \"\"\"\n",
    "    Gets a list of available Amazon Bedrock foundation models.\n",
    "\n",
    "    :return: The list of available bedrock foundation models.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = bedrock_client.list_foundation_models()\n",
    "        models = response[\"modelSummaries\"]\n",
    "        logger.info(\"Got %s foundation models.\", len(models))\n",
    "        return models\n",
    "\n",
    "    except ClientError:\n",
    "        logger.error(\"Couldn't list foundation models.\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def list_granted_foundation_models(bedrock_client):\n",
    "    \"\"\"\n",
    "    Gets a list of available Amazon Bedrock foundation models with granted access.\n",
    "\n",
    "    :return: The list of available bedrock foundation models with granted access.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = bedrock_client.list_foundation_models()\n",
    "        models = response[\"modelSummaries\"]\n",
    "\n",
    "        # 只保留 access == \"GRANTED\" 的\n",
    "        granted_models = [model for model in models if model.get(\"access\") == \"GRANTED\"]\n",
    "\n",
    "        logger.info(\"Got %s granted foundation models.\", len(granted_models))\n",
    "        return granted_models\n",
    "\n",
    "    except ClientError:\n",
    "        logger.error(\"Couldn't list foundation models.\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"Entry point for the example. Uses the AWS SDK for Python (Boto3)\n",
    "    to create an Amazon Bedrock client. Then lists the available Bedrock models\n",
    "    in the region set in the callers profile and credentials.\n",
    "    \"\"\"\n",
    "\n",
    "    bedrock_client = boto3.client(service_name=\"bedrock\")\n",
    "\n",
    "    fm_models = list_granted_foundation_models(bedrock_client)\n",
    "    for model in fm_models:\n",
    "        print(f\"Model: {model['modelName']}\")\n",
    "        print(json.dumps(model, indent=2))\n",
    "        print(\"---------------------------\\n\")\n",
    "\n",
    "    logger.info(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the native inference API to send a text message to Amazon Titan Text G1 - Express.\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create an Amazon Bedrock Runtime client.\n",
    "brt = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# Define the prompt for the model.\n",
    "prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.9\n",
    "    },\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = brt.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the response text.\n",
    "response_text = model_response[\"results\"][0][\"outputText\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "model_id = \"amazon.nova-lite-v1:0\"\n",
    "\n",
    "# 建立一個 Bedrock LLM 實例，指定 model_id\n",
    "llm = BedrockLLM(\n",
    "    model_id=model_id,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.7,\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"topP\": 0.9,\n",
    "        \"stopSequences\": [],\n",
    "    }\n",
    ")\n",
    "\n",
    "# 測試呼叫\n",
    "response = llm.invoke(\"請用中文回答，介紹一下你自己。\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nova & Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Conversation API to send a text message to Amazon Nova.\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create a Bedrock Runtime client in the AWS Region you want to use.\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Set the model ID, e.g., Amazon Nova Lite.\n",
    "model_id = \"amazon.nova-lite-v1:0\"\n",
    "\n",
    "# Start a conversation with the user message.\n",
    "user_message = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=conversation,\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_client = boto3.client('s3', \n",
    "                  region_name='us-east-1')\n",
    "\n",
    "\n",
    "def list_buckets():\n",
    "    response = s3_client.list_buckets()\n",
    "    buckets = response['Buckets']\n",
    "    [print(f\"Bucket Name: {bucket['Name']}\") for bucket in buckets]\n",
    "    return buckets\n",
    "        \n",
    "\n",
    "list_buckets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects(bucket_name, prefix=\"\"):\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=prefix  # 可選：只列出特定開頭的\n",
    "    )\n",
    "    print(f\"Objects in bucket '{bucket_name}':\")\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            print(obj['Key'])\n",
    "    else:\n",
    "        print(\"No objects found.\")\n",
    "\n",
    "# get all objects in all bucket\n",
    "buckets = list_buckets()\n",
    "for bucket in buckets:\n",
    "    list_objects(bucket['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_client = boto3.client('s3', \n",
    "                  region_name='us-east-1')\n",
    "\n",
    "def upload_file_to_s3(bucket_name, file_path, object_name):\n",
    "    try:\n",
    "        s3_client.upload_file(file_path, bucket_name, object_name)\n",
    "        print(f\"File '{file_path}' uploaded to bucket '{bucket_name}' as '{object_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file: {e}\")\n",
    "\n",
    "# upload folder to s3\n",
    "def upload_folder_to_s3(bucket_name, folder_path):\n",
    "    import os\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            object_name = os.path.relpath(file_path, folder_path)\n",
    "            upload_file_to_s3(bucket_name, file_path, object_name)\n",
    "\n",
    "upload_folder_to_s3('aiwave-hackathon-team-8', '../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedrock Knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-east-1'  # 你的 AWS region\n",
    "S3_BUCKET_ARN = 'arn:aws:s3:::your-s3-bucket-name'\n",
    "S3_PREFIX = 'your/s3/folder/'  # S3裡PDF的資料夾，記得最後加斜線/\n",
    "BEDROCK_ROLE_ARN = 'arn:aws:iam::your-account-id:role/your-bedrock-kb-role'\n",
    "EMBEDDING_MODEL_ARN = f'arn:aws:bedrock:{REGION}::foundation-model/amazon.titan-embed-text-v1'\n",
    "\n",
    "COLLECTION_NAME = 'your-collection-name'\n",
    "KB_NAME = 'your-knowledge-base-name'\n",
    "\n",
    "\n",
    "# ====== 建立 Knowledge Base ======\n",
    "bedrock_agent = boto3.client('bedrock-agent', region_name=REGION)\n",
    "\n",
    "print(\"[2] 建立 Knowledge Base...\")\n",
    "create_kb_response = bedrock_agent.create_knowledge_base(\n",
    "    name=KB_NAME,\n",
    "    description=\"Knowledge Base created from S3 PDFs\",\n",
    "    roleArn=BEDROCK_ROLE_ARN,\n",
    "    knowledgeBaseConfiguration={\n",
    "        \"type\": \"VECTOR\",\n",
    "        \"vectorKnowledgeBaseConfiguration\": {\n",
    "            \"embeddingModelArn\": EMBEDDING_MODEL_ARN\n",
    "        }\n",
    "    },\n",
    "    storageConfiguration={\n",
    "        \"type\": \"OPENSEARCH_SERVERLESS\",\n",
    "        \"opensearchServerlessConfiguration\": {\n",
    "            \"collectionArn\": collection_arn,\n",
    "            \"vectorIndexName\": \"bedrock-kb-vector-index\",  # 可以自己改名稱\n",
    "            \"fieldMapping\": {\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"metadata\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "knowledge_base_id = create_kb_response['knowledgeBase']['knowledgeBaseId']\n",
    "print(f\"Knowledge Base 建立成功，ID: {knowledge_base_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stainless-rag-Ca2InKYu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
